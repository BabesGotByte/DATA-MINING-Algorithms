{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-insertion",
   "metadata": {},
   "source": [
    "# Get the transactions as a list of list from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('retail.dat').readlines()\n",
    "transactions = []\n",
    "for line in lines:\n",
    "    transactions.append(line.strip().split())\n",
    "#     total transactions is close to 80k, therefore to execute the code faster\n",
    "    if len(transactions) == 2000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-estate",
   "metadata": {},
   "source": [
    "### In this question, we are asked to perform Apriori using hash function , so we define a function called calc_hash, which gets the hashed value of a particualr itemset. Now using this hash value , we can put that itemset in the corresponding bucket.\n",
    "\n",
    "### This is done in order to remove itemsets with low frequency in one go , for eg , if the number of itemsets in a bucket is less than minimum support then its obvious that none of the candidate itemset in the bucket would be frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considerable-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def calc_hash(itemset,size,val):\n",
    "    power=size-1\n",
    "    hashval=0\n",
    "    for i in itemset:\n",
    "        hashval+=int(i)*(10**power)\n",
    "        power-=1\n",
    "    return hashval%val\n",
    "def getBucket(val,transactions,size,new_itemsets):\n",
    "    C_bucket={}\n",
    "    for i in range(len(transactions)):\n",
    "        for itemset in new_itemsets:\n",
    "            if itemset.issubset(transactions[i]):\n",
    "                hashval=calc_hash(sorted(itemset),size,val)\n",
    "\n",
    "                if hashval in C_bucket:\n",
    "                    C_bucket[hashval].append(sorted(itemset))\n",
    "                else:\n",
    "                    C_bucket[hashval]=[]\n",
    "                    C_bucket[hashval].append(sorted(itemset))\n",
    "    return C_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-heaven",
   "metadata": {},
   "source": [
    "## Now we have to generate C and L for every step of the Algorithm\n",
    "\n",
    "### In this, initially we get all the candidate 1-length itemsets from the transactions and then calculate their frequency. Then , by checking for minimum support for each of the itemsets, we get L (frequent itemsets).\n",
    "\n",
    "### Then in each subsequent step , we generate itemset of length len by the union of itemsets of length len-1. Then we apply the pruning step , to remove the generated itemsets for which not all subsets are frequent. This saves computation afterwards as we have to scan the transaction set again to get the frequency of the generated itemsets. Then generated L using the minimum support value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateL(min_support, L_old, size, transactions,val):\n",
    "    if size>1:\n",
    "        old_itemsets = list(L_old.keys())\n",
    "        new_itemsets = set()\n",
    "        for i in old_itemsets:\n",
    "            for j in old_itemsets:\n",
    "                if len(i.union(j)) == size:\n",
    "                    generated_itemset=i.union(j)\n",
    "                    new_itemsets.add(generated_itemset)\n",
    "\n",
    "        C_bucket=getBucket(val,transactions,size,new_itemsets)\n",
    "        L={}\n",
    "        for i,j in C_bucket.items():\n",
    "            if len(j) >= min_support:\n",
    "                count={}\n",
    "                for itemset in j:\n",
    "                    if frozenset(itemset) in count:\n",
    "                        count[frozenset(itemset)]+=1\n",
    "                    else:\n",
    "                        count[frozenset(itemset)]=1\n",
    "                    for itemset in count:\n",
    "                        if count[itemset] >= min_support:\n",
    "                            L[itemset]=count[itemset]\n",
    "        return L\n",
    "\n",
    "\n",
    "# For 1st iteration\n",
    "    else:\n",
    "        new_itemsets = set()\n",
    "        for i in range(len(transactions)):\n",
    "            for j in range(len(transactions[i])):\n",
    "                new_itemsets.add(frozenset([transactions[i][j]]))\n",
    "        C = {}\n",
    "        for i in range(len(transactions)):\n",
    "            for itemset in new_itemsets:\n",
    "                if itemset.issubset(transactions[i]):\n",
    "                    if itemset in C:\n",
    "                        C[itemset] += 1\n",
    "                    else:\n",
    "                        C[itemset] = 1\n",
    "        L = {}\n",
    "        for i, j in C.items():\n",
    "            if j >= min_support:\n",
    "                L[i] = j\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-absorption",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_support=25\n",
      "min_confidence=0.3\n",
      "buckethash value=25\n",
      "frozenset({'41', '38', '110', '39'})   29 \n",
      "\n",
      "frozenset({'41', '36', '38', '39'})   27 \n",
      "\n",
      "frozenset({'32', '38', '48', '39'})   30 \n",
      "\n",
      "frozenset({'41', '38', '48', '39'})   70 \n",
      "\n",
      "frozenset({'32', '41', '48', '39'})   33 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min_support=25\n",
    "# min_confidence=0.3\n",
    "# val=19\n",
    "min_support=int(input('min_support='))\n",
    "min_confidence=float(input('min_confidence='))\n",
    "val=int(input('buckethash value='))\n",
    "\n",
    "\n",
    "size = 1\n",
    "TL = {}\n",
    "L={}\n",
    "while True:\n",
    "    new_L = generateL(min_support, L, size, transactions,val)\n",
    "    if len(new_L) == 0:\n",
    "        break\n",
    "    TL[size] = new_L\n",
    "    L = new_L\n",
    "    size += 1\n",
    "    \n",
    "for i,j in L.items():\n",
    "    print(i, ' ', j, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suited-dairy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "association_rule \t \t confidence \n",
      "\n",
      "{'110'}->{'38', '39', '41'}   0.3625 \n",
      "\n",
      "{'110', '41'}->{'38', '39'}   0.7631578947368421 \n",
      "\n",
      "{'38', '110'}->{'39', '41'}   0.3815789473684211 \n",
      "\n",
      "{'110', '39'}->{'38', '41'}   0.6904761904761905 \n",
      "\n",
      "{'38', '110', '41'}->{'39'}   0.7837837837837838 \n",
      "\n",
      "{'110', '39', '41'}->{'38'}   1.0 \n",
      "\n",
      "{'38', '110', '39'}->{'41'}   0.7073170731707317 \n",
      "\n",
      "{'36'}->{'38', '39', '41'}   0.32926829268292684 \n",
      "\n",
      "{'36', '41'}->{'38', '39'}   0.75 \n",
      "\n",
      "{'36', '38'}->{'39', '41'}   0.35526315789473684 \n",
      "\n",
      "{'36', '39'}->{'38', '41'}   0.48214285714285715 \n",
      "\n",
      "{'36', '38', '41'}->{'39'}   0.8181818181818182 \n",
      "\n",
      "{'36', '39', '41'}->{'38'}   0.9642857142857143 \n",
      "\n",
      "{'36', '38', '39'}->{'41'}   0.5192307692307693 \n",
      "\n",
      "{'32', '38'}->{'48', '39'}   0.410958904109589 \n",
      "\n",
      "{'32', '38', '48'}->{'39'}   0.8108108108108109 \n",
      "\n",
      "{'32', '38', '39'}->{'48'}   0.5769230769230769 \n",
      "\n",
      "{'32', '48', '39'}->{'38'}   0.30612244897959184 \n",
      "\n",
      "{'38', '41'}->{'48', '39'}   0.42424242424242425 \n",
      "\n",
      "{'48', '38'}->{'39', '41'}   0.36082474226804123 \n",
      "\n",
      "{'48', '38', '41'}->{'39'}   0.8235294117647058 \n",
      "\n",
      "{'38', '39', '41'}->{'48'}   0.5426356589147286 \n",
      "\n",
      "{'48', '39', '41'}->{'38'}   0.3431372549019608 \n",
      "\n",
      "{'48', '38', '39'}->{'41'}   0.4861111111111111 \n",
      "\n",
      "{'32', '41'}->{'48', '39'}   0.4074074074074074 \n",
      "\n",
      "{'32', '48', '41'}->{'39'}   0.7857142857142857 \n",
      "\n",
      "{'32', '39', '41'}->{'48'}   0.5789473684210527 \n",
      "\n",
      "{'32', '48', '39'}->{'41'}   0.336734693877551 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "association_rules = {}\n",
    "for itemset in L:\n",
    "    ele = itemset\n",
    "    for i in range(1, len(itemset)):\n",
    "        for a_set in itertools.combinations(itemset, i):\n",
    "            a_set = frozenset(a_set)\n",
    "            b_set = itemset - a_set\n",
    "            confidence = TL[len(itemset)][itemset] / TL[len(a_set)][a_set]\n",
    "            if confidence >= min_confidence:\n",
    "                association_rules[str(set(a_set)) + '->' + str(set(b_set))] = confidence\n",
    "print('association_rule', '\\t','\\t','confidence','\\n')\n",
    "for i in association_rules:\n",
    "    print(i, ' ', association_rules[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-tracker",
   "metadata": {},
   "source": [
    "## 2nd set of input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "heavy-range",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_support=40\n",
      "min_confidence=0.5\n",
      "buckethash value=35\n",
      "frozenset({'41', '38', '48', '39'})   70 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min_support=25\n",
    "# min_confidence=0.3\n",
    "# val=19\n",
    "min_support=int(input('min_support='))\n",
    "min_confidence=float(input('min_confidence='))\n",
    "val=int(input('buckethash value='))\n",
    "\n",
    "\n",
    "size = 1\n",
    "TL = {}\n",
    "L={}\n",
    "while True:\n",
    "    new_L = generateL(min_support, L, size, transactions,val)\n",
    "    if len(new_L) == 0:\n",
    "        break\n",
    "    TL[size] = new_L\n",
    "    L = new_L\n",
    "    size += 1\n",
    "    \n",
    "for i,j in L.items():\n",
    "    print(i, ' ', j, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "failing-glossary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "association_rule \t \t confidence \n",
      "\n",
      "{'48', '38', '41'}->{'39'}   0.8235294117647058 \n",
      "\n",
      "{'38', '39', '41'}->{'48'}   0.5426356589147286 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "association_rules = {}\n",
    "for itemset in L:\n",
    "    ele = itemset\n",
    "    for i in range(1, len(itemset)):\n",
    "        for a_set in itertools.combinations(itemset, i):\n",
    "            a_set = frozenset(a_set)\n",
    "            b_set = itemset - a_set\n",
    "            confidence = TL[len(itemset)][itemset] / TL[len(a_set)][a_set]\n",
    "            if confidence >= min_confidence:\n",
    "                association_rules[str(set(a_set)) + '->' + str(set(b_set))] = confidence\n",
    "print('association_rule', '\\t','\\t','confidence','\\n')\n",
    "for i in association_rules:\n",
    "    print(i, ' ', association_rules[i], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
