{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM_ASSIGN_9(B).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAODb4yVkYd1"
      },
      "source": [
        "from __future__ import division, print_function\n",
        "import numpy as np\n",
        "import cvxopt\n",
        "from __future__ import division\n",
        "from itertools import combinations_with_replacement\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "from __future__ import division, print_function\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E1-TbElrLTb"
      },
      "source": [
        "\n",
        "def shuffle_data(X, y, seed=None):\n",
        "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "    idx = np.arange(X.shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    return X[idx], y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWarwdp1nH2H"
      },
      "source": [
        "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
        "    \"\"\" Split the data into train and test sets \"\"\"\n",
        "    if shuffle:\n",
        "        X, y = shuffle_data(X, y, seed)\n",
        "    # Split the training data from test data in the ratio specified in\n",
        "    # test_size\n",
        "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
        "    X_train, X_test = X[:split_i], X[split_i:]\n",
        "    y_train, y_test = y[:split_i], y[split_i:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q3k7bW0nPlK"
      },
      "source": [
        "def accuracy_score(y_true, y_pred):\n",
        "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
        "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ0Z2qicj3Hd"
      },
      "source": [
        "\n",
        "# Hide cvxopt output\n",
        "cvxopt.solvers.options['show_progress'] = False\n",
        "\n",
        "class SupportVectorMachine(object):\n",
        "    \"\"\"The Support Vector Machine classifier.\n",
        "    Uses cvxopt to solve the quadratic optimization problem.\n",
        "    Parameters:\n",
        "    -----------\n",
        "    C: float\n",
        "        Penalty term.\n",
        "    kernel: function\n",
        "        Kernel function. Can be either polynomial, rbf or linear.\n",
        "    power: int\n",
        "        The degree of the polynomial kernel. Will be ignored by the other\n",
        "        kernel functions.\n",
        "    gamma: float\n",
        "        Used in the rbf kernel function.\n",
        "    coef: float\n",
        "        Bias term used in the polynomial kernel function.\n",
        "    \"\"\"\n",
        "    def __init__(self, C=1, kernel=rbf_kernel, power=4, gamma=None, coef=4):\n",
        "        self.C = C\n",
        "        self.kernel = kernel\n",
        "        self.power = power\n",
        "        self.gamma = gamma\n",
        "        self.coef = coef\n",
        "        self.lagr_multipliers = None\n",
        "        self.support_vectors = None\n",
        "        self.support_vector_labels = None\n",
        "        self.intercept = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        n_samples, n_features = np.shape(X)\n",
        "\n",
        "        # Set gamma to 1/n_features by default\n",
        "        if not self.gamma:\n",
        "            self.gamma = 1 / n_features\n",
        "\n",
        "        # Initialize kernel method with parameters\n",
        "        self.kernel = self.kernel(\n",
        "            power=self.power,\n",
        "            gamma=self.gamma,\n",
        "            coef=self.coef)\n",
        "\n",
        "        # Calculate kernel matrix\n",
        "        kernel_matrix = np.zeros((n_samples, n_samples))\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                kernel_matrix[i, j] = self.kernel(X[i], X[j])\n",
        "\n",
        "        # Define the quadratic optimization problem\n",
        "        P = cvxopt.matrix(np.outer(y, y) * kernel_matrix, tc='d')\n",
        "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
        "        A = cvxopt.matrix(y, (1, n_samples), tc='d')\n",
        "        b = cvxopt.matrix(0, tc='d')\n",
        "\n",
        "        if not self.C:\n",
        "            G = cvxopt.matrix(np.identity(n_samples) * -1)\n",
        "            h = cvxopt.matrix(np.zeros(n_samples))\n",
        "        else:\n",
        "            G_max = np.identity(n_samples) * -1\n",
        "            G_min = np.identity(n_samples)\n",
        "            G = cvxopt.matrix(np.vstack((G_max, G_min)))\n",
        "            h_max = cvxopt.matrix(np.zeros(n_samples))\n",
        "            h_min = cvxopt.matrix(np.ones(n_samples) * self.C)\n",
        "            h = cvxopt.matrix(np.vstack((h_max, h_min)))\n",
        "\n",
        "        # Solve the quadratic optimization problem using cvxopt\n",
        "        minimization = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "        # Lagrange multipliers\n",
        "        lagr_mult = np.ravel(minimization['x'])\n",
        "\n",
        "        # Extract support vectors\n",
        "        # Get indexes of non-zero lagr. multipiers\n",
        "        idx = lagr_mult > 1e-7\n",
        "        # Get the corresponding lagr. multipliers\n",
        "        self.lagr_multipliers = lagr_mult[idx]\n",
        "        # Get the samples that will act as support vectors\n",
        "        self.support_vectors = X[idx]\n",
        "        # Get the corresponding labels\n",
        "        self.support_vector_labels = y[idx]\n",
        "\n",
        "        # Calculate intercept with first support vector\n",
        "        self.intercept = self.support_vector_labels[0]\n",
        "        for i in range(len(self.lagr_multipliers)):\n",
        "            self.intercept -= self.lagr_multipliers[i] * self.support_vector_labels[\n",
        "                i] * self.kernel(self.support_vectors[i], self.support_vectors[0])\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        # Iterate through list of samples and make predictions\n",
        "        for sample in X:\n",
        "            prediction = 0\n",
        "            # Determine the label of the sample by the support vectors\n",
        "            for i in range(len(self.lagr_multipliers)):\n",
        "                prediction += self.lagr_multipliers[i] * self.support_vector_labels[\n",
        "                    i] * self.kernel(self.support_vectors[i], sample)\n",
        "            prediction += self.intercept\n",
        "            y_pred.append(np.sign(prediction))\n",
        "        return np.array(y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UIfd0AsoGSQ"
      },
      "source": [
        "\n",
        "\n",
        "def main(x,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
        "\n",
        "    clf = SupportVectorMachine(kernel=polynomial_kernel, power=4, coef=1)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print (\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Reduce dimension to two using PCA and plot the results\n",
        "    # Plot().plot_in_2d(X_test, y_pred, title=\"Support Vector Machine\", accuracy=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Zi0Khqj7a5"
      },
      "source": [
        "df = pd.read_csv('ionosphere.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXMWte8noR0x",
        "outputId": "dda0c59f-a4fd-4c36-d035-7be5b7e237cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "      <th>0.99539</th>\n",
              "      <th>-0.05889</th>\n",
              "      <th>0.85243</th>\n",
              "      <th>0.02306</th>\n",
              "      <th>0.83398</th>\n",
              "      <th>-0.37708</th>\n",
              "      <th>1.1</th>\n",
              "      <th>0.03760</th>\n",
              "      <th>0.85243.1</th>\n",
              "      <th>-0.17755</th>\n",
              "      <th>0.59755</th>\n",
              "      <th>-0.44945</th>\n",
              "      <th>0.60536</th>\n",
              "      <th>-0.38223</th>\n",
              "      <th>0.84356</th>\n",
              "      <th>-0.38542</th>\n",
              "      <th>0.58212</th>\n",
              "      <th>-0.32192</th>\n",
              "      <th>0.56971</th>\n",
              "      <th>-0.29674</th>\n",
              "      <th>0.36946</th>\n",
              "      <th>-0.47357</th>\n",
              "      <th>0.56811</th>\n",
              "      <th>-0.51171</th>\n",
              "      <th>0.41078</th>\n",
              "      <th>-0.46168</th>\n",
              "      <th>0.21266</th>\n",
              "      <th>-0.34090</th>\n",
              "      <th>0.42267</th>\n",
              "      <th>-0.54487</th>\n",
              "      <th>0.18641</th>\n",
              "      <th>-0.45300</th>\n",
              "      <th>g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.02337</td>\n",
              "      <td>-0.00592</td>\n",
              "      <td>-0.09924</td>\n",
              "      <td>-0.11949</td>\n",
              "      <td>-0.00763</td>\n",
              "      <td>-0.11824</td>\n",
              "      <td>0.14706</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0.03786</td>\n",
              "      <td>-0.06302</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.04572</td>\n",
              "      <td>-0.15540</td>\n",
              "      <td>-0.00343</td>\n",
              "      <td>-0.10196</td>\n",
              "      <td>-0.11575</td>\n",
              "      <td>-0.05414</td>\n",
              "      <td>0.01838</td>\n",
              "      <td>0.03669</td>\n",
              "      <td>0.01519</td>\n",
              "      <td>0.00888</td>\n",
              "      <td>0.03513</td>\n",
              "      <td>-0.01535</td>\n",
              "      <td>-0.03240</td>\n",
              "      <td>0.09223</td>\n",
              "      <td>-0.07859</td>\n",
              "      <td>0.00732</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.00039</td>\n",
              "      <td>0.12011</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   1  0  0.99539  -0.05889  0.85243  ...  0.42267  -0.54487  0.18641  -0.45300  g\n",
              "0  1  0  1.00000  -0.18829  0.93035  ... -0.16626  -0.06288 -0.13738  -0.02447  b\n",
              "1  1  0  1.00000  -0.03365  1.00000  ...  0.60436  -0.24180  0.56045  -0.38238  g\n",
              "2  1  0  1.00000  -0.45161  1.00000  ...  0.25682   1.00000 -0.32382   1.00000  b\n",
              "3  1  0  1.00000  -0.02401  0.94140  ... -0.05707  -0.59573 -0.04608  -0.65697  g\n",
              "4  1  0  0.02337  -0.00592 -0.09924  ...  0.00000   0.00000 -0.00039   0.12011  b\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P44Jf33iodxi"
      },
      "source": [
        "x = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt0kCPI6pZ2s"
      },
      "source": [
        "x=x.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klcq6wrkpqg7"
      },
      "source": [
        "y=y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcU6cNzvr_3j",
        "outputId": "49a76689-fdb1-4eeb-f207-fb350110507b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBBNL9E7r2IC"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giqEhEmHr9SW",
        "outputId": "b85af994-82e4-4fb6-d4c9-34d771cfd3a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xcB1HO6qLba",
        "outputId": "8f7b1166-2079-4f88-a9a2-a3fbd06fe878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "main(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.33043478260869563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU1OhkbcqpqW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}